---
redirect_from:
  - /backend/sql
---

# SQL API

SQL API enables Cube to deliver data over the [Postgres-compatible
protocol][postgres-protocol] to certain kinds of data applications, including
but not limited to the following ones:

- [Business intelligence (BI) and data exploration][ref-bi] tools, e.g.,
  [Tableau][ref-tableau], [Power BI][ref-powerbi], [Thoughtspot][ref-thoughtspot],
  [Sigma][ref-sigma], [Looker Studio][ref-looker-studio], [Superset /
  Preset][ref-superset], and [Metabase][ref-metabase]
- [Data notebooks][ref-notebooks], e.g., [Jupyter][ref-jupyter], [Hex][ref-hex],
  or [Deepnote][ref-deepnote]
- Reverse ETL tools, e.g., Census or Hightouch

Often, the SQL API is used to enable internal or self-serve [business
intelligence][cube-bi-use-case] use cases.

<InfoBox>

Please use [this GitHub issue](https://github.com/cube-js/cube/issues/3906) to
suggest tools of your interest and vote for already proposed ones.

</InfoBox>

See [SQL API reference][ref-ref-sql-api] for the list of supported commands,
functions, and operators.

## Configuration

### Cube Core

**SQL API is disabled by default.** To enable the SQL API, set `CUBEJS_PG_SQL_PORT`
to a port number you'd like to connect to with a Postgres-compatible tool.

| Credential | Environment variable, etc.     |
|:---------- |:------------------------------ |
| Host       | Host you're running Cube at    |
| Port       | Set via `CUBEJS_PG_SQL_PORT`   |
| User name  | Set via `CUBEJS_SQL_USER`      |
| Password   | Set via `CUBEJS_SQL_PASSWORD`  |
| Database   | Any valid string, e.g., `cube` |

You can also use
[`checkSqlAuth`][ref-config-checksqlauth],
[`canSwitchSqlUser`][ref-config-canswitchsqluser], and `CUBEJS_SQL_SUPER_USER`
to configure [custom authentication][ref-sql-api-auth].

#### Example

The following Docker Compose file will run Cube with the SQL API enabled on
port 15432, accessible using `user` as the user name, `pass` as the password,
and any string as the database name:


```yaml filename="docker-compose.yml"
version: "2.2"
 
services:
  cube:
    image: cubejs/cube:latest
    ports:
      - 4000:4000
      - 15432:15432
    environment:
      - CUBEJS_DEV_MODE=true
      - CUBEJS_API_SECRET=SECRET

      - CUBEJS_DB_USER=cube
      - CUBEJS_DB_PASS=12345
      - CUBEJS_DB_HOST=demo-db-examples.cube.dev
      - CUBEJS_DB_NAME=ecom
      - CUBEJS_DB_TYPE=postgres

      - CUBEJS_PG_SQL_PORT=15432  # SQL API credential
      - CUBEJS_SQL_USER=user      # SQL API credential
      - CUBEJS_SQL_PASSWORD=pass  # SQL API credential
    volumes:
      - .:/cube/conf
```

After running it with `docker compose up`, you can use the [`psql`
utility][link-psql] to test the connection:

```bash
PGPASSWORD=pass psql -h localhost -p 15432 -U user cube
```

### Cube Cloud

**SQL API is enabled by default.** You can find credentials for the SQL API on
theÂ <Btn>Overview</Btn> page by clickingÂ <Btn>Connect to SQL API</Btn>.

By default, the SQL API is enabled on port 5432, the user name is `cube`, and
a random  string is generated for the password. You can customize these with
`CUBEJS_PG_SQL_PORT`, `CUBEJS_SQL_USER`, and `CUBEJS_SQL_PASSWORD` environment
variables by navigating toÂ <Btn>Settings â†’ Configration</Btn>.

You can use the [`psql` utility][link-psql] to test the connection:

```bash
PGPASSWORD=pass \
  psql -h awesome-ecom.sql.gcp-us-central1.cubecloudapp.dev \
  -p 5432 \
  -U cube awesome-ecom
```

## Querying Fundamentals

Under the hood, SQL API uses
[Apache Datafusion](https://arrow.apache.org/datafusion/) as its SQL execution
engine. It's responsible for query planning and execution. As the conversion
process from SQL to Cube Query can be ambiguous, an additional step of query
rewriting is done before the query is executed. During this step, the query plan
is rewritten such that the maximum number of Cube Queries can be detected within
the given query plan. Overall, rewriting is a seamless process. There are some
practical considerations that you should keep in mind while querying, though.

In the SQL API, each cube is represented as a table. Measures, dimensions, and
segments in this table are columns. We call these tables *cube tables*.

Cube supports two querying models with and without SQL Pushdown.
Whenever SQL Pushdown is disabled only Standard Route is active.
Whenever SQL Pushdown is enabled SQL Pushdown Route is active in addition to Standard Route.
Below is detailed explanation of how those two querying models behave.

### Standard Route

Consider the `orders` cube in your data model, the following query is performing
a `SELECT` from the `orders` cube.

```sql
SELECT
  city,
  SUM(amount)
FROM orders
WHERE status = 'shipped'
GROUP BY 1
```

The SQL API transforms `SELECT` query fragments from *cube tables* into
[Cube's internal query format](/product/apis-integrations/rest-api/query-format).
This process is called *Cube query rewrite*.

The SQL query above would be rewritten into the following Cube query:

```json
{
  "measures": ["Orders.amount"],
  "dimensions": ["Orders.city"],
  "filters": [
    {
      "member": "Orders.status",
      "operator": "equals",
      "values": ["shipped"]
    }
  ]
}
```

Because of this transformation, not all functions and expressions are supported
in query fragments performing `SELECT` from cube tables. Please refer to the
reference to see whether a specific expression or function is supported. For
example, the following query won't work because the SQL API can't push down the
`case` expression to Cube for processing. It is not possible to translate `case`
expression in measure.

```sql
-- This query won't work because of the Cube query rewrite
SELECT
  city,
  MAX(CASE
    WHEN status = 'shipped' THEN '2-done'
    ELSE '1-in-progress'
  END) real_status,
  SUM(number)
FROM orders
CROSS JOIN users
GROUP BY 1;
```

You can leverage nested queries in cases like this. You can wrap your `SELECT`
statement from a cube table into another `SELECT` statement to perform
calculations with expressions like `CASE`. This outer select is **not** part of
the SQL query that being rewritten and thus allows you to use more SQL
functions, operators and expressions. You can rewrite the above query as
follows, making sure to wrap the original `SELECT` statement:

```sql
--- You can also use CTEs to achieve the same result
SELECT
  city,
  MAX(CASE
    WHEN status = 'shipped' THEN '2-done'
    ELSE '1-in-progress'
  END) real_status,
  SUM(amount) AS total
FROM (
  SELECT
    users.city AS city,
    SUM(number) AS amount,
    orders.status
  FROM orders
  CROSS JOIN users
  GROUP BY 1, 3
) AS inner
GROUP BY 1, 2
ORDER BY 1;
```

The above query works because the `CASE` expression is supported in `SELECT`
queries **not** querying cube tables.

When querying cube tables, it is important to understand fundamentals of Cube
query rewrite as well as the **pushdown** process. **Pushdown** is a process of
pushing the processing of a particular part of the query down to the inner
`SELECT` from the cube table. The following sections provide an overview of Cube
query rewrite and pushdown. Please refer to the reference to see whether
specific functions, operators or expressions are supported in Cube query
rewrite.

### SQL Pushdown Route

<WarningBox heading={`ðŸ£  Preview`}>

  SQL Pushdown is currently in Preview, and the API and behavior may
  change in a future version.
  SQL Pushdown is disabled by default and is controlled by
  `CUBESQL_SQL_PUSH_DOWN` environment variable.
  In future versions, `CUBESQL_SQL_PUSH_DOWN` will be enabled by default.

</WarningBox>

SQL Pushdown provides a safe net for queries that can't be rewritten
into combination of
[Cube's internal query format](/product/apis-integrations/rest-api/query-format)
and post-processing by
[Datafusion](https://arrow.apache.org/datafusion/).
Such queries SQL would be transpiled to target database query leveraging
all target database capabilities for data processing.
Even when SQL Pushdown is enabled, it has secondary priority to
Standard Route as it provides better cache utilization.

During the rewrite process, Cube validates that the target database would support transpired SQL queries.
If direct conversion is not possible, different SQL transformation rewrite rules can be applied to achieve successful translation.
Please refer to [SQL API reference](/reference/sql-api) for the list of supported SQL functions and clauses.
Support varies based on the target database.

### Top-down vs bottom-up evaluation

Fundamentally, every SQL operation results in a tabular data set.
This is usually referred to as SQL operational closure or bottom-up SQL evaluation.
However, for OLAP queries, most of the time, top-down evaluation is required.
Top-down evaluation is whenever the outermost sub-query operation decides on how measures would be actually evaluated as opposed to
innermost sub-query in case of standard SQL behavior.

To balance between SQL guarantees and OLAP requirements, Cube
- uses top-down evaluation from the innermost aggregation operation down to all ungrouped sub-queries,
- uses bottom-up evaluation from the innermost aggregation tabular result set up to the outermost sub-query.

<WarningBox>

  This behavior is enabled whenever SQL Pushdown is enabled.
  In future versions it'd become default behavior.

</WarningBox>

To drill-down on how this works, let's consider following example date model

```yaml
cubes:
  - name: orders
    sql_table: ECOM.ORDERS

    dimensions:
      - name: id
        sql: ID
        type: number
        primary_key: true

      - name: status
        sql: STATUS
        type: string
        description: The status of the order (completed etc)

      - name: created_at
        sql: "{CUBE}.CREATED_AT"
        type: time

    measures:
      - name: count
        type: count

      - name: completed_count
        type: count
        filters:
          - sql: "{CUBE}.STATUS = 'completed'"

      - name: completed_percentage
        type: number
        sql: "({completed_count} / NULLIF({count}, 0)) * 100.0"
        format: percent
```

And the query to the SQL API:

```sql
SELECT id, status, created_at, completed_percentage FROM orders
```

Such a query is considered an ungrouped query and would result in the following result set:

| id       | status    | created_at |  completed_percentage |
| -------- | --------- | ---------- | --------------------- |
| 1        | shipped   | 2024-01-01 | 0.0                   |
| 2        | completed | 2024-01-01 | 100.0                 |
| 3        | completed | 2024-01-02 | 100.0                 |

On the other hand, a typical query that various BI tools generate

```sql
SELECT date_trunc('day', created_at), MEASURE(completed_percentage)
FROM (
  SELECT id, status, created_at, completed_percentage FROM orders
) inner_query
GROUP BY 1
```

would still yield correct results

| date_trunc('day', created_at) |  completed_percentage |
| ----------------------------- | --------------------- |
| 2024-01-01                    | 50.0                  |
| 2024-01-02                    | 100.0                 |

For this particular query, `inner_query` won't be evaluated as a table.
Instead, Cube would postpone its execution until wrapping `GROUP BY` and would use only `date_trunc('day', created_at)` as a dimension to evaluate `completed_percentage` measure instead of full set of `inner_query` columns `id`,`status` and `created_at`.
To make it possible, Cube keeps track of ungrouped queries and evaluates them only on the first occurrence of a `GROUP BY` query in case there's one.

### Aggregated and non-aggregated queries

SQL API supports two types of queries against *cube tables*: aggregated
(those with `GROUP BY` statement) and non-aggregated (those without).

<InfoBox>

Without SQL Pushdown, Queries that Cube runs against to your database will always be aggregated,
regardless of whether you use aggregated (with `GROUP BY`) or non-aggregated
queries with the SQL API unless SQL Pushdown is enabled.
Whenever you enable SQL Pushdown, queries which do not contain `GROUP BY` clause will be executed as ungrouped queries.

</InfoBox>

A non-aggregated query would only include bare column names in SQL:

```sql
SELECT
  status,  -- dimension
  count    -- measure
FROM orders
```

With SQL Pushdown disabled Cube will still use `GROUP BY` to execute such a query.

<WarningBox>

  In future versions automatic use of `GROUP BY` for every query would be deprecated and disabled by default.

</WarningBox>

Whenever SQL Pushdown is enabled such query would run as ungrouped query.
As with REST API such queries do not use `GROUP BY` and render measures as if those would be grouped by primary key of a cube.

<WarningBox>

  If SQL Pushdown is enabled calculated `number`, `string` or `time` measures queried by SQL API can't use aggregation function definitions with it's `sql` paremeter.
  Such measures can still reference other aggregate type measures though.

</WarningBox>

Aggregated query must aggregate all measure columns and group by
all dimension columns. You can use the special `MEASURE` aggregate function
for measures of [any type][ref-measure-types]. This is quite convenient, especially
in case you're manually writing ad-hoc queries:

```sql
SELECT
  status,         -- dimension
  MEASURE(count)  -- measure
FROM orders
GROUP BY 1
```

<WarningBox>

If any measure columns are not aggregated or any dimension columns aren't included
in `GROUP BY`, the following error will be thrown: `Projection references
non-aggregate values`. This is a standard SQL consistency check for the `GROUP BY`
operation, and it's enforced by the SQL API as well. 

</WarningBox>

Instead of the special `MEASURE` function, measure columns can be aggregated with
the following aggregate functions that correspond to [measure types][ref-measure-types]:

| Measure type in Cube | Aggregate function in an aggregated query |
| --- | --- |
| [`avg`](/reference/data-model/types-and-formats#avg) | `MEASURE` or `AVG` | 
| [`boolean`](/reference/data-model/types-and-formats#boolean) | `MEASURE` |
| [`count`](/reference/data-model/types-and-formats#count) | `MEASURE` or `COUNT` |
| [`count_distinct`](/reference/data-model/types-and-formats#count_distinct) | `MEASURE` or `COUNT(DISTINCT â€¦)` |
| [`count_distinct_approx`](/reference/data-model/types-and-formats#count_distinct_approx) | `MEASURE` or `COUNT(DISTINCT â€¦)` |
| [`max`](/reference/data-model/types-and-formats#max) | `MEASURE` or `MAX` |
| [`min`](/reference/data-model/types-and-formats#min) | `MEASURE` or `MIN` |
| [`number`](/reference/data-model/types-and-formats#number) | `MEASURE` or any other function from this table |
| [`string`](/reference/data-model/types-and-formats#string) | `MEASURE` or `STRING_AGG` |
| [`sum`](/reference/data-model/types-and-formats#sum) | `MEASURE` or `SUM` |
| [`time`](/reference/data-model/types-and-formats#time) | `MEASURE` or `MAX` or `MIN` |

Example query:

```sql
SELECT
  status,         -- dimension
  COUNT(count)    -- measure
FROM orders
GROUP BY 1
```

<WarningBox>

If an aggregate function doesn't match the measure type, the following error
will be thrown: `Measure aggregation type doesn't match`.

</WarningBox>

### Standard Route Filtering

Cube supports most simple equality operators like `=`, `<>`, `<`, `<=`, `>`,
`>=` as well as `IN` and `LIKE` operators. Cube tries to push down all filters
into Cube query. In some cases, SQL filters aren't available in Cube and can be
done in a post-processing phase. Time dimension filters will be converted to
time dimension date ranges whenever it's possible.

### Standard Route Ordering

Cube tries to push down all `ORDER BY` statements into Cube Query.

If it can't be done ordering part would be done in a post-processing phase. In
case there are more than 50,000 rows in the result set, incorrect results can be
received in this case. Please use `EXPLAIN` in order to check if it's the case.

Consider the following query.

```sql
SELECT
  status,
  SUM(total_value) + 2 as transformed_amount
FROM (
  SELECT * FROM orders
) orders
GROUP BY status
ORDER BY status DESC
LIMIT 100
```

Because of the expression `SUM(total_value) + 2` in the projection of outer
query, Cube can't push down `ORDER`.

You can run `EXPLAIN` against the above query to look at the plan. As you can
see below, the sorting operation is done after Cube query and projection.

```bash
+ GlobalLimitExec: skip=None, fetch=100
+- SortExec: [transformed_amount@1 DESC]
+-- ProjectionExec: expr=[status@0 as status, SUM(orders.total_value)@1 + CAST(2 AS Float64) as transformed_amount]
+--- CubeScanExecutionPlan
```

Because of the default limit in Cube queries (50,000 rows), there is a
possibility of a wrong result if there are more than 50,000 rows. Given that
queries to Cube are usually aggregated, it is rare that they may return more
than 50,000 rows, but keep that limitation in mind when designing your queries.

### Standard Route Limit

Limit push down is supported by Cube however, a limit over 50,000 can't be
overridden. In future versions, paging and streaming would be used to avoid this
limitation.

## Examples

Consider the following data model:

<CodeTabs>

```yaml
cubes:
  - name: orders
    sql_table: orders

    measures:
      - name: count
        type: count

    dimensions:
      - name: status
        type: string
        sql: status

      - name: created_at
        type: time
        sql: created_at
```

```javascript
cube(`orders`, {
  sql_table: `orders`,

  measures: {
    count: {
      type: `count`,
    },
  },

  dimensions: {
    status: {
      sql: `status`,
      type: `string`,
    },

    created_at: {
      sql: `created_at`,
      type: `time`,
    },
  },
});
```

</CodeTabs>

It would be represented as table in SQL API with `count`, `status`, `created`
columns.

To get the count of orders grouped by status we can run the following query.

```sql
cube=> SELECT count, status FROM orders;
 count |   status
-------+------------
 15513 | completed
 14652 | processing
 13829 | shipped
(3 rows)
```

Cube will automatically apply the `GROUP BY` clause in case it is missing in the
query. We can also provide the `GROUP BY` statement to control how results are
grouped. In the following example, we group orders by created month and also by
status within every month.

```sql
cube=> SELECT MEASURE(count), status, DATE_TRUNC('month', created_at) date FROM orders GROUP BY date, status ORDER BY date asc;
 measure(orders.count) |   status   |            date
-----------------------+------------+----------------------------
                    31 | shipped    | 2016-01-01 00:00:00.000000
                    28 | completed  | 2016-01-01 00:00:00.000000
                    28 | processing | 2016-01-01 00:00:00.000000
                    28 | shipped    | 2016-02-01 00:00:00.000000
                    18 | processing | 2016-02-01 00:00:00.000000
                    28 | completed  | 2016-02-01 00:00:00.000000
                    54 | processing | 2016-03-01 00:00:00.000000
                    57 | completed  | 2016-03-01 00:00:00.000000
                    56 | shipped    | 2016-03-01 00:00:00.000000
                    54 | shipped    | 2016-04-01 00:00:00.000000
                    60 | completed  | 2016-04-01 00:00:00.000000
                    43 | processing | 2016-04-01 00:00:00.000000
                    55 | shipped    | 2016-05-01 00:00:00.000000
```

### Querying Dimensions

Querying dimensions is straightforward, simply add any required fields to the
`SELECT` clause.

```sql
cube=> SELECT status FROM orders GROUP BY 1;
   status
------------
 completed
 processing
 shipped
(3 rows)
```

### Querying Measures

Measures can similarly be queried through Cube SQL.

```sql
cube=> SELECT MEASURE(count) FROM orders;
 count
-------
 43994
(1 row)
```

Some BI systems or SQL constraints may require you to apply aggregate functions.
To support this, Cube allows aggregate functions on measures as long as they
match the type of the measure.

`count` measure in our example is of type `count`, It means we can apply
`COUNT()` aggregate function to it. The below query is similar to the above one.

```sql
cube=> SELECT COUNT(count) FROM orders;
 COUNT(orders.count)
---------------------
               43994
(1 row)
```

There's also universal aggregate function `MEASURE()` that matches any measure
type.

```sql
cube=> SELECT MEASURE(count) FROM orders;
 measure(orders.count)
-----------------------
                 43994
(1 row)
```

Let's look at more measures types:

<CodeTabs>

```yaml
cubes:
  - name: orders
    # ...

    measures:
      - name: count
        type: count

      - name: distinct_count
        type: count_distinct
        sql: id

      - name: approx_distinct_count
        type: count_distinct_approx
        sql: id

      - name: min_value
        type: min
        sql: min_value

      - name: max_value
        type: max
        sql: max_value
```

```javascript
cube(`orders`, {
  // ...,

  measures: {
    count: {
      type: `count`,
    },
    distinct_count: {
      sql: `id`,
      type: `count_distinct`,
    },
    approx_distinct_count: {
      sql: `id`,
      type: `count_distinct_approx`,
    },
    min_value: {
      sql: `min_value`,
      type: `min`,
    },
    max_value: {
      sql: `max_value`,
      type: `max`,
    },
  },
});
```

</CodeTabs>

As we can see, we have a mix of measure types in the above data model. To query
them, we could use the following SQL statements:

```sql
SELECT COUNT(*) FROM orders
SELECT COUNT(DISTINCT distinct_count) FROM orders
SELECT COUNT(DISTINCT approx_distinct_count) FROM orders
SELECT MIN(min_value) FROM orders
SELECT MAX(max_value) FROM orders
```

### Querying Segments

Any segments defined in a data model can also be used in Cube SQL queries.
Looking at the data model below, we have one segment `is_completed`:

<CodeTabs>

```yaml
cubes:
  - name: orders
    # ...
    segments:
      - name: is_completed
        sql: status = 'completed'
```

```javascript
cube("orders", {
  // ...,

  segments: {
    is_completed: {
      sql: `${CUBE}.status = 'completed'`,
    },
  },
});
```

</CodeTabs>

Segments must be used as `boolean` types in Cube SQL queries:

```sql
WHERE is_completed = true
```

[ref-config-js]: /reference/configuration/config
[ref-dynamic-schemas]: /schema/dynamic-schema-creation
[ref-config-env]: /reference/configuration/environment-variables
[ref-sql-api-auth]: /product/apis-integrations/sql-api/security
[ref-config-checksqlauth]: /reference/configuration/config#checksqlauth
[ref-config-canswitchsqluser]: /reference/configuration/config#canswitchsqluser
[ref-bi]: /product/configuration/visualization-tools#bi-data-exploration-tools
[ref-superset]: /product/configuration/visualization-tools/superset
[ref-tableau]: /product/configuration/visualization-tools/tableau
[ref-powerbi]: /product/configuration/visualization-tools/powerbi
[ref-thoughtspot]: /product/configuration/visualization-tools/thoughtspot
[ref-sigma]: /product/configuration/visualization-tools/sigma
[ref-looker-studio]: /product/configuration/visualization-tools/looker-studio
[ref-metabase]: /product/configuration/visualization-tools/metabase
[ref-notebooks]: /product/configuration/visualization-tools#notebooks
[ref-jupyter]: /product/configuration/visualization-tools/jupyter
[ref-hex]: /product/configuration/visualization-tools/hex
[ref-deepnote]: /product/configuration/visualization-tools/deepnote
[postgres-protocol]: https://www.postgresql.org/docs/current/protocol.html
[cube-bi-use-case]: https://cube.dev/use-cases/connected-bi
[ref-ref-sql-api]: /reference/sql-api
[ref-measure-types]: /reference/data-model/types-and-formats#measure-types
[link-psql]: https://www.postgresql.org/docs/current/app-psql.html
