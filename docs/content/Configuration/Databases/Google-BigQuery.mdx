---
title: Google BigQuery
permalink: /config/databases/google-bigquery
---

## Prerequisites

<InfoBox>

In order to connect Google BigQuery to Cube, you need to provide service account
credentials. Cube requires the service account to have **BigQuery Data Viewer**
and **BigQuery Job User** roles enabled. You can learn more about acquiring
Google BigQuery credentials [here][bq-docs-getting-started].

</InfoBox>

- [The Google Cloud Project ID][google-cloud-docs-projects] for the
  [BigQuery][bq] project
- [A set of Google Cloud service credentials][google-support-create-svc-account]
  [which allow access][bq-docs-getting-started] to the [BigQuery][bq] project
- [The Google Cloud region][bq-docs-regional-locations] for the [BigQuery][bq]
  project

## Setup

### <--{"id" : "Setup"}--> Manual

Add the following to a `.env` file in your Cube project:

```bash
CUBEJS_DB_TYPE=bigquery
CUBEJS_DB_BQ_PROJECT_ID=my-bigquery-project-12345
CUBEJS_DB_BQ_KEY_FILE=/path/to/my/keyfile.json
```

You could also encode the key file using Base64 and set the result to
`CUBEJS_DB_BQ_CREDENTIALS`:

```bash
CUBEJS_DB_BQ_CREDENTIALS=$(cat /path/to/my/keyfile.json | base64)
```

## Environment Variables

| Environment Variable           | Description                                                                                                                                                                                     | Possible Values                                                         | Required | [Supports multiple data sources?][ref-config-multiple-ds-decorating-env] |
| ------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------- | :------: | :----------------------------------------------------------------------: |
| `CUBEJS_DB_BQ_PROJECT_ID`      | The Google BigQuery project ID to connect to                                                                                                                                                    | A valid Google BigQuery Project ID                                      |    ✅    |                                    ✅                                    |
| `CUBEJS_DB_BQ_KEY_FILE`        | The path to a JSON key file for connecting to Google BigQuery                                                                                                                                   | A valid Google BigQuery JSON key file                                   |    ✅    |                                    ✅                                    |
| `CUBEJS_DB_BQ_CREDENTIALS`     | A Base64 encoded JSON key file for connecting to Google BigQuery                                                                                                                                | A valid Google BigQuery JSON key file encoded as a Base64 string        |    ❌    |                                    ✅                                    |
| `CUBEJS_DB_BQ_LOCATION`        | The Google BigQuery dataset location to connect to. Required if used with pre-aggregations outside of US. If not set then BQ driver will fail with `Dataset was not found in location US` error | [A valid Google BigQuery regional location][bq-docs-regional-locations] |    ⚠️    |                                    ✅                                    |
| `CUBEJS_DB_EXPORT_BUCKET`      | The name of a bucket in cloud storage                                                                                                                                                           | A valid bucket name from cloud storage                                  |    ❌    |                                    ✅                                    |
| `CUBEJS_DB_EXPORT_BUCKET_TYPE` | The cloud provider where the bucket is hosted                                                                                                                                                   | `gcp`                                                                   |    ❌    |                                    ✅                                    |
| `CUBEJS_CONCURRENCY`           | The number of concurrent connections each queue has to the database. Default is `10`                                                                                                            | A valid number                                                          |    ❌    |                                    ❌                                    |
| `CUBEJS_DB_MAX_POOL`           | The maximum number of concurrent database connections to pool. Default is `40`                                                                                                                  | A valid number                                                          |    ❌    |                                    ✅                                    |

## Pre-Aggregation Feature Support

### countDistinctApprox

Measures of type
[`countDistinctApprox`][ref-schema-ref-types-formats-countdistinctapprox] can be
used in pre-aggregations when using Google BigQuery as a source database. To
learn more about Google BigQuery's support for approximate aggregate functions,
[click here][bq-docs-approx-agg-fns].

## Pre-Aggregation Build Strategies

<InfoBox>

To learn more about pre-aggregation build strategies, [head
here][ref-caching-using-preaggs-build-strats].

</InfoBox>

| Feature       | Works with read-only mode? | Is default? |
| ------------- | :------------------------: | :---------: |
| Batching      |             ❌             |     ✅      |
| Export Bucket |             ❌             |     ❌      |

By default, Google BigQuery uses [batching][self-preaggs-batching] to build
pre-aggregations.

### Batching

No extra configuration is required to configure batching for Google BigQuery.

### Export bucket

<WarningBox>

BigQuery only supports using Google Cloud Storage for export buckets.

</WarningBox>

#### Google Cloud Storage

For [improved pre-aggregation performance with large
datasets][ref-caching-large-preaggs], enable export bucket functionality by
configuring Cube with the following environment variables:

<InfoBox>

When using an export bucket, remember to assign the **BigQuery Data Editor** and
**Storage Object Admin** role to your BigQuery service account.

</InfoBox>

```bash
CUBEJS_DB_EXPORT_BUCKET=export_data_58148478376
CUBEJS_DB_EXPORT_BUCKET_TYPE=gcp
```

## SSL

Cube does not require any additional configuration to enable SSL as Google
BigQuery connections are made over HTTPS.

[bq]: https://cloud.google.com/bigquery
[bq-docs-getting-started]:
  https://cloud.google.com/docs/authentication/getting-started
[bq-docs-credentials]:
  https://console.cloud.google.com/apis/credentials/serviceaccountkey
[bq-docs-regional-locations]:
  https://cloud.google.com/bigquery/docs/locations#regional-locations
[bq-docs-approx-agg-fns]:
  https://cloud.google.com/bigquery/docs/reference/standard-sql/approximate_aggregate_functions
[google-cloud-docs-projects]:
  https://cloud.google.com/resource-manager/docs/creating-managing-projects#before_you_begin
[google-support-create-svc-account]:
  https://support.google.com/a/answer/7378726?hl=en
[ref-caching-large-preaggs]: /caching/using-pre-aggregations#export-bucket
[ref-caching-using-preaggs-build-strats]:
  /caching/using-pre-aggregations#pre-aggregation-build-strategies
[ref-config-multiple-ds-decorating-env]:
  /config/multiple-data-sources#configuring-data-sources-with-environment-variables-decorated-environment-variables
[ref-schema-ref-types-formats-countdistinctapprox]:
  /schema/reference/types-and-formats#count-distinct-approx
[self-preaggs-batching]: #batching
