---
title: SQL API
permalink: /backend/sql
category: API Reference
menuOrder: 3
---

<WarningBox heading={`Migration to Postgres protocol`}>

  This is documentation of Cubeâ€™s SQL API for the Postgres protocol.
  The MySQL protocol used in the first versions of the Cube SQL API is no longer being developed and will be phased out soon.
  Please consider migrating to the Postgres protocol.

</WarningBox>

The Cube SQL API allows querying Cube via Postgres-compatible SQL. It enables the use
of BI applications, Python notebooks, reverse ETL tools, and other downstream tools on top of
Cube.

### <--{"id" : "SQL API"}--> Supported Tools

Cube SQL API has been tested with psql CLI, Apache Superset, Tableau Cloud, Tableau Desktop with JDBC driver and PowerBI.
Please see [this GitHub issue](https://github.com/cube-js/cube.js/issues/3906) for the tools roadmap and to suggest and vote for tools of your interest.

### <--{"id" : "SQL API"}--> Cube Cloud

The first step to get started with the SQL API in Cube Cloud is to create a
deployment. You can follow this
[step-by-step guide on creating deployment within Cube Cloud](/cloud/getting-started/create).

Once the deployment is ready, click **How to connect** link on the Overview page.
It will open a modal with instructions on different ways to connect to Cube.
Navigate to the SQL API tab and enable the SQL API.

Once it is enabled, you should see a screen like the one below with your
connection credentials.

<div style="text-align: center">
  <img
    src="https://raw.githubusercontent.com/cube-js/cube.js/master/docs/content/cube-sql-api-modal.png"
    style="border: none"
    width="80%"
  />
</div>

Since the Cube SQL API is Postgres-compatible, please make sure to select **Postgres** as
a database type when connecting from BI tools.

### <--{"id" : "SQL API"}--> Self-hosted Cube

To enable the SQL API, we first need to add a new environment variable:

```dotenv
CUBEJS_PG_SQL_PORT=5432
```

If you're running Cube with Docker, remember to add a port mapping to the Cube
service for `CUBEJS_PG_SQL_PORT`. Docker compose example:

```yaml
services:
  cube_api:
    ...
    ports:
      - 5432:5432 # Cube SQL API
```

Or running docker from command line:

```bash
docker run -p 4000:4000 -p 5432:5432 \
  -v ${PWD}:/cube/conf \
  -e CUBEJS_DEV_MODE=true \
  -e CUBEJS_PG_SQL_PORT=5432 \
  cubejs/cube
```

Then, set Cube SQL credentials auth:

```
CUBEJS_SQL_USER=myusername
CUBEJS_SQL_PASSWORD=mypassword
```

Now, you can start your Cube instance and connect via the `psql` client with
provided credentials:

```bash
psql -h 127.0.0.1 --port 5432 -U myusername --password
```

## Querying Fundamentals

Under the hood, SQL API uses [Apache Datafusion](https://arrow.apache.org/datafusion/) as its SQL execution engine.
It's responsible for query planning and execution.
As the conversion process from SQL to Cube Query is ambiguous, additional step is done before the query is executed.
This step is called rewriting.
During this step, the query plan is being rewritten in a way a maximum number of Cube Queries can be detected within the given query plan.
Overall, rewriting is a seamless process.
There're some practical considerations that you should keep in mind while querying, though.

### <--{"id" : "Querying Fundamentals"}--> Cube is a table

In order to simplify interaction with data tools, every cube is represented as a table.
Measures, dimensions, and segments in this table are columns.
However, not all queries are possible on these tables.
In order to be valid, query against cube table should be:

1. valid SQL statement and be compilable to the initial query plan by Datafusion;
2. one of the supported query types to the cube so it can be converted to Cube Query.

Let's discuss some of the supported query types.

### <--{"id" : "Querying Fundamentals"}--> Aggregated vs Non-aggregated queries

There're two types of queries supported against cube tables: aggregated and non-aggregated.
Aggregated are those with `GROUP BY` statement, and non-aggregated are those without it.
Cube Queries issued to your database will always be aggregated, and it doesn't matter if you provide `GROUP BY` in a query or not.

Whenever you use a non-aggregated query you need to provide only column names in SQL:

```
SELECT status, count FROM Orders
```

The same aggregated query should always aggregate measure columns using a corresponding aggregating function or special `MEASURE()` function:

<WarningBox>

  In cases where measure columns are not aggregated `Projection references non-aggregate values` error will be thrown.
  It means there're columns that are neither in `GROUP BY` or aggregated.
  It's a standard SQL `GROUP BY` operation consistency check enforced by SQL API as well.

</WarningBox>

```
SELECT status, SUM(count) FROM Orders GROUP BY 1
SELECT status, MEASURE(count) FROM Orders GROUP BY 1
```

### <--{"id" : "Querying Fundamentals"}--> Filtering

Cube supports most of simple equality operators like `=`, `<>`, `<`, `<=`, `>`, `>=` as well as `IN` and `LIKE` operators.
Cube tries to push down all filters into Cube Query.
In some cases, SQL filters aren't available in Cube and can be done in a post-processing phase.
Time dimension filters will be converted to time dimension date ranges whenever it's possible.

### <--{"id" : "Querying Fundamentals"}--> Ordering

Cube tries to push down all `ORDER BY` statements into Cube Query.
If it can't be done ordering part would be done in a post-processing phase.
In case there're more than 50k rows in the result set, incorrect results can be received in this case.
Please use `EXPLAIN` in order to check if it's the case.

### <--{"id" : "Querying Fundamentals"}--> Limit

Limit push down is supported by Cube however, a limit over 50k can't be overridden.
In future versions, paging and streaming would be used to avoid this limitation.

## Examples

Consider the following schema.

```js
cube(`Orders`, {
  sql: `SELECT * FROM public.orders`,

  measures: {
    count: {
      type: `count`,
    },
  },

  dimensions: {
    status: {
      sql: `status`,
      type: `string`,
    },

    created: {
      sql: `created_at`,
      type: `time`,
    },
  },
});
```

It would be represented as table in SQL API with `count`, `status`, `created`
columns.

To get the count of orders grouped by status we can run the following query.

```
cube=> SELECT count, status FROM Orders;
 count |   status
-------+------------
 15513 | completed
 14652 | processing
 13829 | shipped
(3 rows)
```

Cube will automatically apply the `GROUP BY` clause in case it is missing in the
query. We can also provide the `GROUP BY` statement to control how results are
grouped. In the following example we group orders by created month and also by
status within every month.

```
cube=> SELECT MEASURE(count), status, DATE_TRUNC('month', createdAt) date FROM Orders GROUP BY date, status ORDER BY date asc;
 measure(Orders.count) |   status   |            date
-----------------------+------------+----------------------------
                    31 | shipped    | 2016-01-01 00:00:00.000000
                    28 | completed  | 2016-01-01 00:00:00.000000
                    28 | processing | 2016-01-01 00:00:00.000000
                    28 | shipped    | 2016-02-01 00:00:00.000000
                    18 | processing | 2016-02-01 00:00:00.000000
                    28 | completed  | 2016-02-01 00:00:00.000000
                    54 | processing | 2016-03-01 00:00:00.000000
                    57 | completed  | 2016-03-01 00:00:00.000000
                    56 | shipped    | 2016-03-01 00:00:00.000000
                    54 | shipped    | 2016-04-01 00:00:00.000000
                    60 | completed  | 2016-04-01 00:00:00.000000
                    43 | processing | 2016-04-01 00:00:00.000000
                    55 | shipped    | 2016-05-01 00:00:00.000000
```

### <--{"id" : "Examples"}--> Querying Dimensions

Querying dimensions is straightforward, simply add any required fields to the
`SELECT` clause.

```sql
cube=> SELECT status FROM Orders;
   status
------------
 completed
 processing
 shipped
(3 rows)
```

### <--{"id" : "Examples"}--> Querying Measures

Measures can similarly be queried through Cube SQL.

Because measures are already aggregated in Cube there is no need to apply
aggregate functions to them in SQL API if you don't have a `GROUP BY` statement in query.

```
cube=> SELECT count FROM Orders;
 count
-------
 43994
(1 row)
```

Some of the BI systems or SQL constraints may require you to apply aggregate functions. To support
this Cube allows aggregate functions on measures as long as they match the type
of the measure.

`count` measure in our example is of type `count`, It means we can apply
`COUNT()` aggregate function to it. The below query is similiar to the above
one.

```
cube=> SELECT COUNT(count) FROM Orders;
 COUNT(Orders.count)
---------------------
               43994
(1 row)
```

There's also universal aggregate function `MEASURE()` that matches any measure type.

```
cube=> SELECT MEASURE(count) FROM Orders;
 measure(Orders.count)
-----------------------
                 43994
(1 row)
```

Let's look at more measures types:

```javascript
cube('Orders', {
  ...,

  measures: {
    count: {
      type: `count`,
    },
    distinctCount: {
      sql: `id`,
      type: `countDistinct`,
    },
    approxDistinctCount: {
      sql: `id`,
      type: `countDistinctApprox`,
    },
    minValue: {
      sql: `min_value`,
      type: `min`
    },
    maxValue: {
      sql: `max_value`,
      type: `max`
    },
  },
})
```

As we can see, we have a mix of measure types in the above schema. To query
them, we could use the following SQL statements:

```sql
--- Both the following statements are equivalent
SELECT count FROM Orders
SELECT COUNT(*) FROM Orders

--- Count distinct, and count distinct approx
--- Both the following statements are equivalent
SELECT distinctCount FROM Orders
SELECT COUNT(DISTINCT distinctCount) FROM Orders

--- Both the following statements are equivalent
SELECT approxDistinctCount FROM Orders
SELECT COUNT(DISTINCT approxDistinctCount) FROM Orders

--- Both the following statements are equivalent
SELECT minValue FROM Orders
SELECT MIN(minValue) FROM Orders

--- Both the following statements are equivalent
SELECT maxValue FROM Orders
SELECT MAX(maxValue) FROM Orders
```

### <--{"id" : "Examples"}--> Querying Segments

Any segments defined in a schema can also be used in Cube SQL queries. Looking
at the schema below, we have one segment `isCompleted`:

```javascript
cube('Orders', {
  ...,

  segments: {
    isCompleted: {
      sql: `${CUBE}.status = 'completed'`,
    },
  },
});
```

Segments must be used as `boolean` types in Cube SQL queries:

```sql
WHERE isCompleted = true
```

## Custom Authentication

Cube can be configured with dynamic username & password verification system by
setting a [`checkSqlAuth()`][ref-config-check-sql-auth] function in the
`cube.js` configuration file. This function should verify username and return
object with password and security context.

If password returned from this function matches provided in connection string
user will be authenticated with provided security context.

```javascript
module.exports = {
  checkSqlAuth: async (req, username) => {
    if (username === 'fooUser') {
      return {
        password: 'mypassword',
        securityContext: {},
      };
    }

    throw new Error('Incorrect user name or password');
  },
};
```

## Security Context (Row-Level Security)

Cube's SQL API can also use the Security Context for
[Dynamic Schema Creation][ref-dynamic-schemas] or [`queryRewrite`][ref-config-queryrewrite] property in your [`cube.js`
configuration file][ref-config-js].

By default, the SQL API uses the current user's Security Context, but this behaviour can be modified so that certain users are allowed to switch. To do this, we must first define which user is allowed to change Security Context:

First, you need to define what user is allowed to change security context:

```
CUBEJS_SQL_SUPER_USER=admin
```

If it's not enough for your case, you define your logic for check with `canSwitchSqlUser` property in your [`cube.js`
configuration file][ref-config-js].

You can change security context for specific query via virtual filter on:

```sql
SELECT * FROM Orders WHERE __user = 'anotheruser';
```

## Joins

SQL API currently does not support `INNER JOIN`, `LEFT JOIN`, `RIGHT JOIN` and `FULL OUTER JOIN`. 
We plan to support these types of joins in future releases.

SQL API supports `CROSS JOIN` between cubes.
When `CROSS JOIN` is being processed by Cube, it generates proper joining conditions for the underlying data backend.

For example, the following query joins `Orders` and `Products` tables under the hood by `product_id` in `Orders` and `id` in `Products` exactly the same way as the REST API query does:

```sql
cube=> SELECT * FROM Orders CROSS JOIN Products LIMIT 5;
 count | avgValue | totalValue | number | value |  status   |         createdAt          |        completedAt         | __user | count |           name            |            description             |         createdAt          | __user 
-------+----------+------------+--------+-------+-----------+----------------------------+----------------------------+--------+-------+---------------------------+------------------------------------+----------------------------+--------
     1 |       20 |         20 |     40 |    20 | completed | 2020-10-26 00:00:00.000000 | 2020-11-07 00:00:00.000000 |        |     1 | Incredible Fresh Chicken  | Electronics Generic Fresh Computer | 2020-06-29 00:00:00.000000 | 
     1 |       20 |         20 |     14 |    20 | completed | 2021-02-07 00:00:00.000000 | 2021-03-02 00:00:00.000000 |        |     1 | Unbranded Wooden Mouse    | Outdoors Incredible Rubber Car     | 2019-07-16 00:00:00.000000 | 
     1 |       20 |         20 |     23 |    20 | completed | 2022-07-23 00:00:00.000000 | 2022-08-11 00:00:00.000000 |        |     1 | Handcrafted Plastic Chair | Electronics Sleek Rubber Tuna      | 2021-02-27 00:00:00.000000 | 
     1 |       20 |         20 |     86 |    20 | completed | 2023-04-19 00:00:00.000000 | 2023-04-25 00:00:00.000000 |        |     1 | Practical Metal Chicken   | Toys Awesome Frozen Chips          | 2020-07-24 00:00:00.000000 | 
     1 |       20 |         20 |     27 |    20 | completed | 2019-06-27 00:00:00.000000 | 2019-07-21 00:00:00.000000 |        |     1 | Sleek Rubber Chair        | Computers Refined Cotton Shirt     | 2021-09-26 00:00:00.000000 | 
(5 rows)
```

In the resulting query plan, you won't see any joins as you can't see those for REST API queries either:

```sql
cube=> EXPLAIN SELECT * FROM Orders CROSS JOIN Products LIMIT 5;
   plan_type   |            plan             
---------------+-----------------------------
 logical_plan  | CubeScan: request={        +
               |   "measures": [            +
               |     "Orders.count",        +
               |     "Orders.avgValue",     +
               |     "Orders.totalValue",   +
               |     "Orders.number",       +
               |     "Products.count"       +
               |   ],                       +
               |   "dimensions": [          +
               |     "Orders.value",        +
               |     "Orders.status",       +
               |     "Orders.createdAt",    +
               |     "Orders.completedAt",  +
               |     "Products.name",       +
               |     "Products.description",+
               |     "Products.createdAt"   +
               |   ],                       +
               |   "segments": [],          +
               |   "limit": 5               +
               | }
 physical_plan | CubeScanExecutionPlan      +
               | 
(2 rows)
```

This feature allows you to `CROSS JOIN` cubes even with transitive joins only.

Typically in tools that allow defining custom SQL datasets, you'd use joined tables as a dataset SQL.
For example:

```sql
SELECT o.count as count, p.name as product_name, p.description as product_description FROM Orders o CROSS JOIN Products p
```
Please note we use aliasing to avoid name clashing between cube members in a resulting data set.
In this case, wrapped SQL will be properly processed by Cube, pushing down all operations to Cube query:

```sql
cube=> SELECT product_name, SUM(count) FROM (
  SELECT o.count as count, p.name as product_name, p.description as product_description FROM Orders o CROSS JOIN Products p
) joined
GROUP BY 1 
ORDER BY 2 DESC 
LIMIT 5;
       product_name       | SUM(joined.count) 
--------------------------+-------------------
 Tasty Plastic Mouse      |               121
 Intelligent Cotton Ball  |               119
 Ergonomic Steel Tuna     |               116
 Intelligent Rubber Pants |               116
 Generic Wooden Gloves    |               116
(5 rows)
```

We can see this by introspecting explain plan for this query:

```sql
cube=> EXPLAIN SELECT product_name, SUM(count) FROM (
  SELECT o.count as count, p.name as product_name, p.description as product_description FROM Orders o CROSS JOIN Products p
) joined
GROUP BY 1 
ORDER BY 2 DESC 
LIMIT 5;
   plan_type   |         plan          
---------------+-----------------------
 logical_plan  | CubeScan: request={  +
               |   "measures": [      +
               |     "Orders.count"   +
               |   ],                 +
               |   "dimensions": [    +
               |     "Products.name"  +
               |   ],                 +
               |   "segments": [],    +
               |   "order": [         +
               |     [                +
               |       "Orders.count",+
               |       "desc"         +
               |     ]                +
               |   ],                 +
               |   "limit": 5         +
               | }
 physical_plan | CubeScanExecutionPlan+
               | 
(2 rows)
```

Please note even if `product_description` is in the inner selection, it isn't evaluated in the final query as it isn't used in any way.

As an alternative to achieve joins it is also possible to define proxy dimension or measure inside the
Cube.

```js
cube(`Orders`, {
  sql: `SELECT * FROM public.orders`,

  joins: {
    Users: {
      relationship: `belongsTo`,
      sql: `${CUBE}.user_id = ${Users}.id`,
    },
  },

  measures: {
    count: {
      type: `count`,
    },
  },

  dimensions: {
    id: {
      sql: `id`,
      type: `number`,
      primaryKey: true,
    },

    // this is proxy dimension
    user_city: {
      sql: `${Users.city}`,
      type: `string`,
    },
  },
});

cube(`Users`, {
  sql: `SELECT * FROM public.users`,

  measures: {},

  dimensions: {
    id: {
      sql: `id`,
      type: `number`,
      primaryKey: true,
    },

    city: {
      sql: `city`,
      type: `string`,
    },
  },
});
```

Now, it is possible to get orders count by users city with the following query.

```
cube=> SELECT count, user_city FROM Orders;
 count |   user_city
-------+---------------
  9524 | New York
  9408 | San Francisco
  6360 | Mountain View
  6262 | Seattle
  4393 | Los Angeles
  3183 | Chicago
  3060 | Austin
  1804 | Palo Alto
(8 rows)
```

## Limitations

### <--{"id" : "Limitations"}--> Projection

`SELECT` statements only support the following projections:

**`*` for all dimensions:**

```sql
SELECT * FROM Orders;
```

**A valid expression for a dimension or measure:**

```sql
SELECT COUNT(*) FROM Orders;
```

**A valid expression as an alias:**

```sql
SELECT COUNT(*) AS order_count FROM Orders;
```

### <--{"id" : "Limitations"}--> Selection

Cube SQL supports most conditional checks for the `WHERE` clause.

**Comparison operators:**

```sql
WHERE price > 50
WHERE price >= 50 AND <= 100
```

**Boolean logic:**

```sql
WHERE isPaid = true
  AND isCompleted = false
  OR isReviewed = false
```

**`IN` operator:**:

```sql
WHERE status IN ('completed', 'shipped')
WHERE status NOT IN ('processing')
```

**`IS NULL`:**

```sql
WHERE completedAt IS NULL
WHERE completedAt IS NOT NULL
```

**`LIKE`:**

```sql
WHERE name LIKE 'joe'
WHERE name NOT LIKE 'bloggs'
```

[ref-config-check-sql-auth]: /config#check-sql-auth
[ref-config-queryrewrite]: /config#query-rewrite
[ref-config-js]: /config
[ref-dynamic-schemas]: /schema/dynamic-schema-creation
