---
title: SQL API
permalink: /backend/sql
category: API Reference
menuOrder: 3
---

<WarningBox heading={`Migration to Postgres protocol`}>

  This is documentation of Cube SQL API for Postgres protocol.
  MySQL protocol used in the first versions of Cube SQL API is not being developed anymore and will be phased out soon.
  Please consider migrating to the Postgres protocol.

</WarningBox>

Cube SQL API allows querying Cube via Postgres-compatible SQL. It enables the use
of BIs, Python Notebooks, Reverse ETLs, and other downstream tools on top of
Cube.

### Cube Cloud

The first step to get started with SQL API in Cube Cloud is to create a
deployment. You can follow this
[step-by-step guide on creating deployment within Cube Cloud](/cloud/getting-started/create).

Once the deployment is ready click **How to connect** link on the Overview page.
It will open the modal with instructions on different ways to connect to Cube,
navigate to the SQL API tab and enable the SQL API.

Once it is enabled you should see the screen like the one below with your
connection credentials.

<div style="text-align: center">
  <img
    src="https://raw.githubusercontent.com/cube-js/cube.js/master/docs/content/cube-sql-api-modal.png"
    style="border: none"
    width="80%"
  />
</div>

Since Cube SQL API is Postgres-compatible, please make sure to select **Postgres** as
a database type when connecting from BI tools.

### Self-hosted Cube

To enable the SQL API, we first need to add a new environment variable:

```dotenv
CUBEJS_PG_SQL_PORT=5432
```

If you're running Cube with Docker, remember to add a port mapping to the Cube
service for `CUBEJS_PG_SQL_PORT`. Docker compose example:

```yaml
services:
  cube_api:
    ...
    ports:
      - 5432:5432 # Cube SQL API
```

Then, set Cube SQL credentials auth:

```
CUBEJS_SQL_USER=myusername
CUBEJS_SQL_PASSWORD=mypassword
```

Now, you can start your Cube instance and connect via the `psql` client with
provided credentials:

```bash
psql -h 127.0.0.1 --port 5432 -U myusername --password
```

## Querying Fundamentals

Under the hood, SQL API uses [Apache Datafusion](https://arrow.apache.org/datafusion/) as its SQL execution engine.
It's responsible for query planning and execution.
As the conversion process from SQL to Cube Query is ambiguous, additional step is done before the query is executed.
This step is called rewriting.
During this step, the query plan is being rewritten in a way a maximum number of Cube Queries can be detected within the given query plan.
Overall, rewriting is a seamless process.
There're some practical considerations that you should keep in mind while querying, though.

### Cube is a table

In order to simplify interaction with data tools, every cube is represented as a table.
Measures, dimensions, and segments in this table are columns.
However, not all queries are possible on these tables.
In order to be valid, query against cube table should be:

1. valid SQL statement and be compilable to the initial query plan by Datafusion;
2. one of the supported query types to the cube so it can be converted to Cube Query.

Let's discuss some of the supported query types.

### Aggregated vs Non-aggregated queries

There're two types of queries supported against cube tables: aggregated and non-aggregated.
Aggregated are those with `GROUP BY` statement, and non-aggregated are those without it.
Cube Queries issued to your database will always be aggregated, and it doesn't matter if you provide `GROUP BY` in a query or not.

### Filtering

Cube supports most of simple equality operators like `=`, `<>`, `<`, `<=`, `>`, `>=` as well as `IN` and `LIKE` operators.
Cube tries to push down all filters into Cube Query.
In some cases, SQL filters aren't available in Cube and can be done in a post-processing phase.
Time dimension filters will be converted to time dimension date ranges whenever it's possible.

### Ordering

Cube tries to push down all `ORDER BY` statements into Cube Query.
If it can't be done ordering part would be done in a post-processing phase.
In case there're more than 50k rows in the result set, incorrect results can be received in this case.
Please use `EXPLAIN` in order to check if it's the case.

### Limit

Limit push down is supported by Cube however, a limit over 50k can't be overridden.
In future versions, paging and streaming would be used to avoid this limitation.

## Examples

Consider the following schema.

```js
cube(`Orders`, {
  sql: `SELECT * FROM public.orders`,

  measures: {
    count: {
      type: `count`,
    },
  },

  dimensions: {
    status: {
      sql: `status`,
      type: `string`,
    },

    created: {
      sql: `created_at`,
      type: `time`,
    },
  },
});
```

It would be represented as table in SQL API with `count`, `status`, `created`
columns.

To get the count of orders grouped by status we can run the following query.

```
cube=> SELECT count, status FROM Orders;
 count |   status
-------+------------
 15513 | completed
 14652 | processing
 13829 | shipped
(3 rows)
```

Cube will automatically apply the `GROUP BY` clause in case it is missing in the
query. We can also provide the `GROUP BY` statement to control how results are
grouped. In the following example we group orders by created month and also by
status within every month.

```
cube=> SELECT MEASURE(count), status, DATE_TRUNC('month', createdAt) date FROM Orders GROUP BY date, status ORDER BY date asc;
 measure(Orders.count) |   status   |            date
-----------------------+------------+----------------------------
                    31 | shipped    | 2016-01-01 00:00:00.000000
                    28 | completed  | 2016-01-01 00:00:00.000000
                    28 | processing | 2016-01-01 00:00:00.000000
                    28 | shipped    | 2016-02-01 00:00:00.000000
                    18 | processing | 2016-02-01 00:00:00.000000
                    28 | completed  | 2016-02-01 00:00:00.000000
                    54 | processing | 2016-03-01 00:00:00.000000
                    57 | completed  | 2016-03-01 00:00:00.000000
                    56 | shipped    | 2016-03-01 00:00:00.000000
                    54 | shipped    | 2016-04-01 00:00:00.000000
                    60 | completed  | 2016-04-01 00:00:00.000000
                    43 | processing | 2016-04-01 00:00:00.000000
                    55 | shipped    | 2016-05-01 00:00:00.000000
```

### Querying Dimensions

Querying dimensions is straightforward, simply add any required fields to the
`SELECT` clause.

```sql
cube=> SELECT status FROM Orders;
   status
------------
 completed
 processing
 shipped
(3 rows)
```

### Querying Measures

Measures can similarly be queried through Cube SQL.

Because measures are already aggregated in Cube there is no need to apply
aggregate functions to them in SQL API if you don't have a `GROUP BY` statement in query.

```
cube=> SELECT count FROM Orders;
 count
-------
 43994
(1 row)
```

Some of the BI systems or SQL constraints may require you to apply aggregate functions. To support
this Cube allows aggregate functions on measures as long as they match the type
of the measure.

`count` measure in our example is of type `count`, It means we can apply
`COUNT()` aggregate function to it. The below query is similiar to the above
one.

```
cube=> SELECT COUNT(count) FROM Orders;
 COUNT(Orders.count)
---------------------
               43994
(1 row)
```

There's also universal aggregate function `MEASURE()` that matches any measure type.

```
cube=> SELECT MEASURE(count) FROM Orders;
 measure(Orders.count)
-----------------------
                 43994
(1 row)
```

Let's look at more measures types:

```javascript
cube('Orders', {
  ...,

  measures: {
    count: {
      type: `count`,
    },
    distinctCount: {
      sql: `id`,
      type: `countDistinct`,
    },
    approxDistinctCount: {
      sql: `id`,
      type: `countDistinctApprox`,
    },
    minValue: {
      sql: `min_value`,
      type: `min`
    },
    maxValue: {
      sql: `max_value`,
      type: `max`
    },
  },
})
```

As we can see, we have a mix of measure types in the above schema. To query
them, we could use the following SQL statements:

```sql
--- Both the following statements are equivalent
SELECT count FROM Orders
SELECT COUNT(*) FROM Orders

--- Count distinct, and count distinct approx
--- Both the following statements are equivalent
SELECT distinctCount FROM Orders
SELECT COUNT(DISTINCT distinctCount) FROM Orders

--- Both the following statements are equivalent
SELECT approxDistinctCount FROM Orders
SELECT COUNT(DISTINCT approxDistinctCount) FROM Orders

--- Both the following statements are equivalent
SELECT minValue FROM Orders
SELECT MIN(minValue) FROM Orders

--- Both the following statements are equivalent
SELECT maxValue FROM Orders
SELECT MAX(maxValue) FROM Orders
```

### Querying Segments

Any segments defined in a schema can also be used in Cube SQL queries. Looking
at the schema below, we have one segment `isCompleted`:

```javascript
cube('Orders', {
  ...,

  segments: {
    isCompleted: {
      sql: `${CUBE}.status = 'completed'`,
    },
  },
});
```

Segments must be used as `boolean` types in Cube SQL queries:

```sql
WHERE isCompleted = true
```

## Custom Authentication

Cube can be configured with dynamic username & password verification system by
setting a [`checkSqlAuth()`][ref-config-check-sql-auth] function in the
`cube.js` configuration file. This function should verify username and return
object with password and security context.

If password returned from this function matches provided in connection string
user will be authenticated with provided security context.

```javascript
module.exports = {
  checkSqlAuth: async (req, username) => {
    const userInfo = await getUserFromLDAP(username);
    if (userInfo) {
      return {
        password: 'mypassword',
        securityContext: {},
      };
    }

    throw new Error('Incorrect user name or password');
  },
};
```

## Limitations

### Projection

`SELECT` statements only support the following projections:

**`*` for all dimensions:**

```sql
SELECT * FROM Orders;
```

**A valid expression for a dimension or measure:**

```sql
SELECT COUNT(*) FROM Orders;
```

**A valid expression as an alias:**

```sql
SELECT COUNT(*) AS order_count FROM Orders;
```

### Selection

Cube SQL supports most conditional checks for the `WHERE` clause.

**Comparison operators:**

```sql
WHERE price > 50
WHERE price >= 50 AND <= 100
```

**Boolean logic:**

```sql
WHERE isPaid = true
  AND isCompleted = false
  OR isReviewed = false
```

**`IN` operator:**:

```sql
WHERE status IN ('completed', 'shipped')
WHERE status NOT IN ('processing')
```

**`IS NULL`:**

```sql
WHERE completedAt IS NULL
WHERE completedAt IS NOT NULL
```

**`LIKE`:**

```sql
WHERE name LIKE 'joe'
WHERE name NOT LIKE 'bloggs'
```

### Joins

SQL API currently does not support joins. We plan to support joins in future
releases.

As a workaround, it is possible to define proxy dimension or measure inside the
Cube.

```js
cube(`Orders`, {
  sql: `SELECT * FROM public.orders`,

  joins: {
    Users: {
      relationship: `belongsTo`,
      sql: `${CUBE}.user_id = ${Users}.id`,
    },
  },

  measures: {
    count: {
      type: `count`,
    },
  },

  dimensions: {
    id: {
      sql: `id`,
      type: `number`,
      primaryKey: true,
    },

    // this is proxy dimension
    user_city: {
      sql: `${Users.city}`,
      type: `string`,
    },
  },
});

cube(`Users`, {
  sql: `SELECT * FROM public.users`,

  measures: {},

  dimensions: {
    id: {
      sql: `id`,
      type: `number`,
      primaryKey: true,
    },

    city: {
      sql: `city`,
      type: `string`,
    },
  },
});
```

Now, it is possible to get orders count by users city with the following query.

```
cube=> SELECT count, user_city FROM Orders;
 count |   user_city
-------+---------------
  9524 | New York
  9408 | San Francisco
  6360 | Mountain View
  6262 | Seattle
  4393 | Los Angeles
  3183 | Chicago
  3060 | Austin
  1804 | Palo Alto
(8 rows)
```

[ref-config-check-sql-auth]: /config#check-sql-auth
